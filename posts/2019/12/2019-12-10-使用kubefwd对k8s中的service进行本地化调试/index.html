<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="大家都知道,k8s中的服务(service)是对k8s中的deployment等对象的一个一致访问点.所以service会有一个vip(headless service没有).无论是普通service的vip或者headless service的pod ip其实都是k8s集群中的内部ip,在集群内访问它是非常容易的.比如有一个service叫nginx,我们在集群内的另一个pod里既可以对这个nginx service的vip进行get访问,也可以通过coredns对这个nginx service的域名如(nginx, nginx.default等)进行访问.但是在集群外呢?这就麻烦了.\n常见的集群外访问service的方式大致分为 LoadBalance, NodePort, ExternalIp等方式, 再细致一点也可以通过Ingress在7层做一层分发再外接上述流量接入,甚至你可以直接将api server做proxy. 很显然的，这些方式如果在我们只是需要对服务进行调试或者随便用用的场景都是要么太复杂(Ingress), 要么花钱(LoadBanlence),要么不靠谱(NodePort).\n这时候你会说,嗷,我们可以使用kubectl port-forward 功能,将service的端口port-forward到本地端口.对，没错，这确实是一个不错的解决方式，但这仍然存在非常多的问题。\n比如,我们并不想要将nginx service的80端口port-forward到我的8080端口上，就想用80端口，那么如果有两个service分别叫nginx1和nginx2，这不就没法弄了吗？再比如，如果我们port-forward的svc的pod发生了变动,怎么办？再比如,我们就是想像在集群内一样，通过service的内部域名对其访问(nginx, nginx.default等)，怎么办？再比如，如果我们有100个服务，难道我们要手动对每个服务port-forward然后手动选择一个没用过的端口吗？甚至，当我们的服务创建,删除,我们又得手动操作,这是何等的麻烦？\n基于上述问题,一个叫kubefwd的工具出现了。\n"><title>使用kubefwd对k8s中的service进行本地化调试</title><link rel=canonical href=https://www.calmkart.com/posts/2019/12/2019-12-10-%E4%BD%BF%E7%94%A8kubefwd%E5%AF%B9k8s%E4%B8%AD%E7%9A%84service%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%E5%8C%96%E8%B0%83%E8%AF%95/><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap"><link rel=stylesheet href=/scss/style.min.390cc81d180d80110703ea467e355a4f3a0f44f25d4e957842790824fb5f2ef2.css><meta property='og:title' content="使用kubefwd对k8s中的service进行本地化调试"><meta property='og:description' content="大家都知道,k8s中的服务(service)是对k8s中的deployment等对象的一个一致访问点.所以service会有一个vip(headless service没有).无论是普通service的vip或者headless service的pod ip其实都是k8s集群中的内部ip,在集群内访问它是非常容易的.比如有一个service叫nginx,我们在集群内的另一个pod里既可以对这个nginx service的vip进行get访问,也可以通过coredns对这个nginx service的域名如(nginx, nginx.default等)进行访问.但是在集群外呢?这就麻烦了.\n常见的集群外访问service的方式大致分为 LoadBalance, NodePort, ExternalIp等方式, 再细致一点也可以通过Ingress在7层做一层分发再外接上述流量接入,甚至你可以直接将api server做proxy. 很显然的，这些方式如果在我们只是需要对服务进行调试或者随便用用的场景都是要么太复杂(Ingress), 要么花钱(LoadBanlence),要么不靠谱(NodePort).\n这时候你会说,嗷,我们可以使用kubectl port-forward 功能,将service的端口port-forward到本地端口.对，没错，这确实是一个不错的解决方式，但这仍然存在非常多的问题。\n比如,我们并不想要将nginx service的80端口port-forward到我的8080端口上，就想用80端口，那么如果有两个service分别叫nginx1和nginx2，这不就没法弄了吗？再比如，如果我们port-forward的svc的pod发生了变动,怎么办？再比如,我们就是想像在集群内一样，通过service的内部域名对其访问(nginx, nginx.default等)，怎么办？再比如，如果我们有100个服务，难道我们要手动对每个服务port-forward然后手动选择一个没用过的端口吗？甚至，当我们的服务创建,删除,我们又得手动操作,这是何等的麻烦？\n基于上述问题,一个叫kubefwd的工具出现了。\n"><meta property='og:url' content='https://www.calmkart.com/posts/2019/12/2019-12-10-%E4%BD%BF%E7%94%A8kubefwd%E5%AF%B9k8s%E4%B8%AD%E7%9A%84service%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%E5%8C%96%E8%B0%83%E8%AF%95/'><meta property='og:site_name' content='cAlm的个人Blog'><meta property='og:type' content='article'><meta property='article:section' content='Posts'><meta property='article:tag' content='k8s'><meta property='article:tag' content='kubefwd'><meta property='article:tag' content='kubernetes'><meta property='article:published_time' content='2019-12-10T00:00:00+00:00'><meta property='article:modified_time' content='2019-12-10T00:00:00+00:00'><meta name=twitter:title content="使用kubefwd对k8s中的service进行本地化调试"><meta name=twitter:description content="大家都知道,k8s中的服务(service)是对k8s中的deployment等对象的一个一致访问点.所以service会有一个vip(headless service没有).无论是普通service的vip或者headless service的pod ip其实都是k8s集群中的内部ip,在集群内访问它是非常容易的.比如有一个service叫nginx,我们在集群内的另一个pod里既可以对这个nginx service的vip进行get访问,也可以通过coredns对这个nginx service的域名如(nginx, nginx.default等)进行访问.但是在集群外呢?这就麻烦了.\n常见的集群外访问service的方式大致分为 LoadBalance, NodePort, ExternalIp等方式, 再细致一点也可以通过Ingress在7层做一层分发再外接上述流量接入,甚至你可以直接将api server做proxy. 很显然的，这些方式如果在我们只是需要对服务进行调试或者随便用用的场景都是要么太复杂(Ingress), 要么花钱(LoadBanlence),要么不靠谱(NodePort).\n这时候你会说,嗷,我们可以使用kubectl port-forward 功能,将service的端口port-forward到本地端口.对，没错，这确实是一个不错的解决方式，但这仍然存在非常多的问题。\n比如,我们并不想要将nginx service的80端口port-forward到我的8080端口上，就想用80端口，那么如果有两个service分别叫nginx1和nginx2，这不就没法弄了吗？再比如，如果我们port-forward的svc的pod发生了变动,怎么办？再比如,我们就是想像在集群内一样，通过service的内部域名对其访问(nginx, nginx.default等)，怎么办？再比如，如果我们有100个服务，难道我们要手动对每个服务port-forward然后手动选择一个没用过的端口吗？甚至，当我们的服务创建,删除,我们又得手动操作,这是何等的麻烦？\n基于上述问题,一个叫kubefwd的工具出现了。\n"></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column compact"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><div class=site-meta><h1 class=site-name><a href=/>cAlm的个人Blog</a></h1><h2 class=site-description>随手记录些东西</h2></div></header><ol class=menu id=main-menu><li><a href=/><span>首页</span></a></li><li><a href=/archives><span>归档</span></a></li><li><a href=/categories><span>分类</span></a></li><li><a href=/about><span>关于</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/ style=background-color:#bed8ef;color:#0f283d>计算机</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/posts/2019/12/2019-12-10-%E4%BD%BF%E7%94%A8kubefwd%E5%AF%B9k8s%E4%B8%AD%E7%9A%84service%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%E5%8C%96%E8%B0%83%E8%AF%95/>使用kubefwd对k8s中的service进行本地化调试</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published datetime=2019-12-10T00:00:00Z>Tuesday, December 10, 2019</time></div></footer></div></header><section class=article-content><p>大家都知道,k8s中的服务(service)是对k8s中的deployment等对象的一个一致访问点.所以service会有一个vip(headless service没有).无论是普通service的vip或者headless service的pod ip其实都是k8s集群中的内部ip,在集群内访问它是非常容易的.比如有一个service叫nginx,我们在集群内的另一个pod里既可以对这个nginx service的vip进行get访问,也可以通过coredns对这个nginx service的域名如(nginx, nginx.default等)进行访问.但是在集群外呢?这就麻烦了.</p><p>常见的集群外访问service的方式大致分为 LoadBalance, NodePort, ExternalIp等方式, 再细致一点也可以通过Ingress在7层做一层分发再外接上述流量接入,甚至你可以直接将api server做proxy. 很显然的，这些方式如果在我们只是需要对服务进行调试或者随便用用的场景都是要么太复杂(Ingress), 要么花钱(LoadBanlence),要么不靠谱(NodePort).</p><p>这时候你会说,嗷,我们可以使用kubectl port-forward 功能,将service的端口port-forward到本地端口.对，没错，这确实是一个不错的解决方式，但这仍然存在非常多的问题。</p><p>比如,我们并不想要将nginx service的80端口port-forward到我的8080端口上，就想用80端口，那么如果有两个service分别叫nginx1和nginx2，这不就没法弄了吗？再比如，如果我们port-forward的svc的pod发生了变动,怎么办？再比如,我们就是想像在集群内一样，通过service的内部域名对其访问(nginx, nginx.default等)，怎么办？再比如，如果我们有100个服务，难道我们要手动对每个服务port-forward然后手动选择一个没用过的端口吗？甚至，当我们的服务创建,删除,我们又得手动操作,这是何等的麻烦？</p><p>基于上述问题,一个叫<a class=link href=https://github.com/txn2/kubefwd target=_blank rel=noopener>kubefwd</a>的工具出现了。</p><p>我们先从使用开始。 首先有一个集群,有nginx和nginx1两个service,其中nginx是普通service,而nginx1是headless service.</p><pre tabindex=0><code>➜  ~ kubectl get pods
NAME                                 READY   STATUS      RESTARTS   AGE
nginx-deployment-5cdfb5fc49-fgn78    1/1     Running     0          24d
nginx-deployment-5cdfb5fc49-rjg26    1/1     Running     0          24d
nginx-deployment1-75c5577b94-tp7zr   1/1     Running     0          21d
nginx-deployment1-75c5577b94-vcpn5   1/1     Running     0          21d
pi-gw8s7                             0/1     Completed   0          74d
➜  ~ kubectl get service
NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1               443/TCP   74d
nginx        ClusterIP   10.101.159.59           80/TCP    33d
nginx1       ClusterIP   None                    80/TCP    21d
➜  ~
</code></pre><p>然后我们下载最新版的kubefwd(<a class=link href=https://github.com/txn2/kubefwd/releases target=_blank rel=noopener>release</a>)在本地运行。</p><pre tabindex=0><code>➜  kubefwd git:(master) sudo kubefwd svc
Password:
INFO[11:44:47]  _          _           __             _
INFO[11:44:47] | | ___   _| |__   ___ / _|_      ____| |
INFO[11:44:47] | |/ / | | | &#39;_ \ / _ \ |_\ \ /\ / / _  |
INFO[11:44:47] |   &lt;| |_| | |_) |  __/  _|\ V  V / (_| |
INFO[11:44:47] |_|\_\\__,_|_.__/ \___|_|   \_/\_/ \__,_|
INFO[11:44:47]
INFO[11:44:47] Version 0.0.0
INFO[11:44:47] https://github.com/txn2/kubefwd
INFO[11:44:47]
INFO[11:44:47] Press [Ctrl-C] to stop forwarding.
INFO[11:44:47] &#39;cat /etc/hosts&#39; to see all host entries.
INFO[11:44:47] Loaded hosts file /etc/hosts
INFO[11:44:47] Hostfile management: Original hosts backup already exists at /Users/calmkart/hosts.original
WARN[11:44:47] WARNING: No Pod selector for service kubernetes in default on cluster .
INFO[11:44:47] Forwarding: nginx1:80 to pod nginx-deployment1-75c5577b94-tp7zr:80
INFO[11:44:47] Forwarding: nginx-deployment1-75c5577b94-tp7zr.nginx1:80 to pod nginx-deployment1-75c5577b94-tp7zr:80
INFO[11:44:47] Forwarding: nginx-deployment1-75c5577b94-vcpn5.nginx1:80 to pod nginx-deployment1-75c5577b94-vcpn5:80
INFO[11:44:47] Forwarding: nginx:80 to pod nginx-deployment-5cdfb5fc49-fgn78:80
</code></pre><p>我们可以通过控制台INFO输出清晰的看到,我们已经将普通service nginx port-forward到了它的第一个pod nginx-deployment-5cdfb5fc49-fgn78上，将headless service nginx1 port-forward到了它的第一个pod上，同时还port-forward到了它的每一个pod上(因为headless service中的pod是不等价的).</p><p>接着我们查看一下本机的hosts</p><pre tabindex=0><code>➜  ~ cat /etc/hosts
##
# Host Database
#
# localhost is used to configure the loopback interface
# when the system is booting.  Do not change this entry.
##
127.0.0.1        localhost
127.1.27.1       nginx1 nginx1.default.svc.cluster.local nginx1.default
127.1.27.2       nginx-deployment1-75c5577b94-tp7zr.nginx1 nginx-deployment1-75c5577b94-tp7zr.nginx1.default.svc.cluster.local nginx-deployment1-75c5577b94-tp7zr.nginx1.default
127.1.27.3       nginx-deployment1-75c5577b94-vcpn5.nginx1 nginx-deployment1-75c5577b94-vcpn5.nginx1.default.svc.cluster.local nginx-deployment1-75c5577b94-vcpn5.nginx1.default
127.1.27.4       nginx nginx.default.svc.cluster.local nginx.default
</code></pre><p>厉害了，居然多出了这么多记录。 从这个hosts看起来，我们访问nginx1/nginx1.default.svc.cluster.local/nginx1.default应该都可以访问到k8s集群中的nginx1服务; 我们访问nginx/nginx.default.svc.cluster.local/nginx.default应该都可以访问到k8s集群中的nginx服务,我们来尝试一下。 使用httpie试试</p><pre tabindex=0><code>➜  ~ http get nginx1
HTTP/1.1 200 OK
Accept-Ranges: bytes
Connection: keep-alive
Content-Length: 612
Content-Type: text/html
Date: Tue, 10 Dec 2019 03:57:05 GMT
ETag: &#34;58e66cf5-264&#34;
Last-Modified: Thu, 06 Apr 2017 16:29:41 GMT
Server: nginx/1.11.13

➜  ~ http get nginx
HTTP/1.1 200 OK
Accept-Ranges: bytes
Connection: keep-alive
Content-Length: 612
Content-Type: text/html
Date: Tue, 10 Dec 2019 03:57:17 GMT
ETag: &#34;54999765-264&#34;
Last-Modified: Tue, 23 Dec 2014 16:25:09 GMT
Server: nginx/1.7.9
</code></pre><p>厉害了也，真的管用。</p><p>我们尝试在k8s集群中新添加一个service叫nginx2,这个服务和nginx1一样是一个headless service</p><pre tabindex=0><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment2
  labels:
    app: nginx2
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx2
  template:
    metadata:
      labels:
        app: nginx2
        test: test
        test1: test1
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
        readinessProbe:
          tcpSocket:
            port: 80
        livenessProbe:
          tcpSocket:
            port: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx2
spec:
  clusterIP: None
  selector:
    app: nginx2
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
</code></pre><p> </p><pre tabindex=0><code>➜  ~ kubectl apply -f nginx2.yaml
deployment.apps/nginx-deployment2 created
service/nginx2 created
</code></pre><p>这个时候我们发现运行的kubefwd INFO记录显示了如下内容</p><pre tabindex=0><code>INFO[12:01:12] Forwarding: nginx2:80 to pod nginx-deployment2-5995ddf44f-6r9fg:80
INFO[12:01:12] Forwarding: nginx-deployment2-5995ddf44f-6r9fg.nginx2:80 to pod nginx-deployment2-5995ddf44f-6r9fg:80
INFO[12:01:12] Forwarding: nginx-deployment2-5995ddf44f-d5q9d.nginx2:80 to pod nginx-deployment2-5995ddf44f-d5q9d:80
</code></pre><p>我们来看看Hosts</p><pre tabindex=0><code>127.1.27.5       nginx2 nginx2.default.svc.cluster.local nginx2.default
127.1.27.6       nginx-deployment2-5995ddf44f-6r9fg.nginx2 nginx-deployment2-5995ddf44f-6r9fg.nginx2.default.svc.cluster.local nginx-deployment2-5995ddf44f-6r9fg.nginx2.default
127.1.27.7       nginx-deployment2-5995ddf44f-d5q9d.nginx2 nginx-deployment2-5995ddf44f-d5q9d.nginx2.default.svc.cluster.local nginx-deployment2-5995ddf44f-d5q9d.nginx2.default
</code></pre><p>果然，新添加了这些记录。看来我们通过本地域名解析nginx2就可以访问到nginx2服务啦.我们来试试.</p><pre tabindex=0><code>➜  ~ http get nginx2
HTTP/1.1 200 OK
Accept-Ranges: bytes
Connection: keep-alive
Content-Length: 612
Content-Type: text/html
Date: Tue, 10 Dec 2019 04:03:23 GMT
ETag: &#34;5dd3e500-264&#34;
Last-Modified: Tue, 19 Nov 2019 12:50:08 GMT
Server: nginx/1.17.6
</code></pre><p>果然，和我们预想的一样。 最后我们通过ctrl+c停止kubefwd.</p><pre tabindex=0><code>^CWARN[12:04:08] Stopped forwarding nginx-deployment1-75c5577b94-vcpn5.nginx1 in default.
WARN[12:04:08] Stopped forwarding nginx-deployment2-5995ddf44f-d5q9d.nginx2 in default.
WARN[12:04:08] Stopped forwarding nginx2 in default.
WARN[12:04:08] Stopped forwarding nginx in default.
WARN[12:04:08] Stopped forwarding nginx-deployment2-5995ddf44f-6r9fg.nginx2 in default.
WARN[12:04:08] Stopped forwarding nginx1 in default.
WARN[12:04:08] Stopped forwarding nginx-deployment1-75c5577b94-tp7zr.nginx1 in default.
INFO[12:04:08] Done...
</code></pre><p>terminal中显示我们停止了nginx,nginx1,nginx2的转发,我们再来看看hosts呢？</p><pre tabindex=0><code>##
# Host Database
#
# localhost is used to configure the loopback interface
# when the system is booting.  Do not change this entry.
##
127.0.0.1        localhost
</code></pre><p>果然，已经清理完毕了。</p><p>以上基本就是常规使用的全过程，接下来大致讲讲原理吧。</p><p>kubefwd项目过去的运行机制是在运行时通过api-server拉取k8s中的所有service服务信息(List),并将服务分为普通服务和无头服务两类,通过普通服务的第一个pod/无头服务的每一个pod的port-forward subresource对其做转发,并在本地为其创建无人使用的环回接口ip,将其转发上去,实现端口的隔离。</p><p>后来代码经过我的一次很大的重构,目前的流程是像一个自定义控制器一样,在启动时ListAndWatch api-server的service信息，能够自动感知api-server的服务变化，当服务被创建/删除，服务转发的pod被修改/删除时开启对应的goroutine对其进行port-forward并修改Hosts(过程中加锁).当kubefwd被停止时(或者某service被删除时)启动清理流程，结束转发并清理hosts.</p><p>其实原理上并不复杂，但确实是能在k8s环境中解决某一个方向上的问题的。 欢迎大家来试着使用使用。</p><hr><h2 id=历史评论-1-条>历史评论 (1 条)</h2><p><em>以下评论来自原 WordPress 站点，仅作存档展示。</em></p><blockquote><p><strong>1</strong> (2019-12-16 17:03)</p><p>1</p></blockquote></section><footer class=article-footer><section class=article-tags><a href=/tags/k8s/>K8s</a>
<a href=/tags/kubefwd/>Kubefwd</a>
<a href=/tags/kubernetes/>Kubernetes</a></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/posts/2019/10/2019-10-21-%E4%BD%BF%E7%94%A8kubectl-debug%E6%9D%A5%E8%B0%83%E8%AF%95pod/><div class=article-details><h2 class=article-title>使用kubectl-debug来调试pod</h2></div></a></article><article><a href=/posts/2019/09/2019-09-18-kubernetes-scheduler%E6%B5%81%E7%A8%8B%E5%9B%BE/><div class=article-details><h2 class=article-title>kubernetes scheduler流程图</h2></div></a></article><article><a href=/posts/2019/08/2019-08-22-%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8kube-prometheus/><div class=article-details><h2 class=article-title>配置和使用kube-prometheus</h2></div></a></article><article><a href=/posts/2019/06/2019-06-13-kubernetesjenkins%E5%AE%9E%E7%8E%B0%E7%8E%B0%E4%BB%A3cicd%E6%B5%81%E6%B0%B4%E7%BA%BF%E4%B8%80/><div class=article-details><h2 class=article-title>kubernetes+jenkins实现现代cicd流水线(一)</h2></div></a></article><article><a href=/posts/2019/05/2019-05-25-kubernetes%E9%9B%86%E7%BE%A4%E4%B8%AD%E6%9C%8D%E5%8A%A1%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%92%8C%E5%A4%96%E9%83%A8%E5%8F%91%E7%8E%B0/><div class=article-details><h2 class=article-title>kubernetes集群中服务的负载均衡和外部发现</h2></div></a></article></div></div></aside><div id=tcomment></div><script src=https://cdn.jsdelivr.net/npm/twikoo@1.6.39/dist/twikoo.all.min.js></script><script>twikoo.init({envId:"calmblog.vercel.app",el:"#tcomment",lang:"zh-CN"})</script><footer class=site-footer><section class=copyright>&copy;
2026 cAlm的个人Blog</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=4.0.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><script type=module>
    import gallery from '\/ts\/gallery.js';

    const articleContent = document.querySelector('.article-content');
    const shouldLoad = articleContent && (articleContent.querySelectorAll('figure').length > 0 || articleContent.querySelectorAll('img.gallery-image').length > 0);
    
    if (shouldLoad) {
        gallery(articleContent);

        const PhotoSwipeLightbox = (await import("https:\/\/cdn.jsdelivr.net\/npm\/photoswipe@5.4.4\/dist\/photoswipe-lightbox.esm.min.js")).default;
        const styleHref = "https:\/\/cdn.jsdelivr.net\/npm\/photoswipe@5.4.4\/dist\/photoswipe.css";

        const styleTag = document.createElement('link');
        styleTag.rel = 'stylesheet';
        styleTag.href = styleHref;
        document.head.appendChild(styleTag);

        const lightbox = new PhotoSwipeLightbox({
            gallerySelector: '.article-content',
            childSelector: 'figure a.image-link',
            pswpModule: () => import("https:\/\/cdn.jsdelivr.net\/npm\/photoswipe@5.4.4\/dist\/photoswipe.esm.min.js")
        });
        lightbox.init();
    }
</script></main></div><script type=text/javascript src=/ts/main.acaf849f2b273f6a8368a58b001f336738d0c948d92e79b116467d0c7515f932.js defer></script></body></html>