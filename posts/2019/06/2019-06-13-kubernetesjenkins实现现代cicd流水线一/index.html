<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="前面几篇文章已经谈过在k8s中如何实现rook/ceph持久化存储和服务发现/负载均衡/服务暴露策略，接下来几篇文章将以springboot项目为例，详解如何利用kubernetes容器编排平台实现cicd流水线(devops)。\n"><title>kubernetes+jenkins实现现代cicd流水线(一)</title><link rel=canonical href=https://www.calmkart.com/posts/2019/06/2019-06-13-kubernetesjenkins%E5%AE%9E%E7%8E%B0%E7%8E%B0%E4%BB%A3cicd%E6%B5%81%E6%B0%B4%E7%BA%BF%E4%B8%80/><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap"><link rel=stylesheet href=/scss/style.min.390cc81d180d80110703ea467e355a4f3a0f44f25d4e957842790824fb5f2ef2.css><meta property='og:title' content="kubernetes+jenkins实现现代cicd流水线(一)"><meta property='og:description' content="前面几篇文章已经谈过在k8s中如何实现rook/ceph持久化存储和服务发现/负载均衡/服务暴露策略，接下来几篇文章将以springboot项目为例，详解如何利用kubernetes容器编排平台实现cicd流水线(devops)。\n"><meta property='og:url' content='https://www.calmkart.com/posts/2019/06/2019-06-13-kubernetesjenkins%E5%AE%9E%E7%8E%B0%E7%8E%B0%E4%BB%A3cicd%E6%B5%81%E6%B0%B4%E7%BA%BF%E4%B8%80/'><meta property='og:site_name' content='cAlm的个人Blog'><meta property='og:type' content='article'><meta property='article:section' content='Posts'><meta property='article:tag' content='cicd'><meta property='article:tag' content='devops'><meta property='article:tag' content='jenkins'><meta property='article:tag' content='k8s'><meta property='article:tag' content='kubernetes'><meta property='article:tag' content='自定义slave'><meta property='article:published_time' content='2019-06-13T00:00:00+00:00'><meta property='article:modified_time' content='2019-06-13T00:00:00+00:00'><meta name=twitter:title content="kubernetes+jenkins实现现代cicd流水线(一)"><meta name=twitter:description content="前面几篇文章已经谈过在k8s中如何实现rook/ceph持久化存储和服务发现/负载均衡/服务暴露策略，接下来几篇文章将以springboot项目为例，详解如何利用kubernetes容器编排平台实现cicd流水线(devops)。\n"></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column compact"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><div class=site-meta><h1 class=site-name><a href=/>cAlm的个人Blog</a></h1><h2 class=site-description>随手记录些东西</h2></div></header><ol class=menu id=main-menu><li><a href=/><span>首页</span></a></li><li><a href=/archives><span>归档</span></a></li><li><a href=/categories><span>分类</span></a></li><li><a href=/about><span>关于</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/ style=background-color:#bed8ef;color:#0f283d>计算机</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/posts/2019/06/2019-06-13-kubernetesjenkins%E5%AE%9E%E7%8E%B0%E7%8E%B0%E4%BB%A3cicd%E6%B5%81%E6%B0%B4%E7%BA%BF%E4%B8%80/>kubernetes+jenkins实现现代cicd流水线(一)</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published datetime=2019-06-13T00:00:00Z>Thursday, June 13, 2019</time></div></footer></div></header><section class=article-content><p>前面几篇文章已经谈过在k8s中如何实现rook/ceph持久化存储和服务发现/负载均衡/服务暴露策略，接下来几篇文章将以springboot项目为例，详解如何利用kubernetes容器编排平台实现cicd流水线(devops)。</p><p>我们根据上面几篇文章已经有了一个k8s集群，常见的的cicd工具有jenkins，gitlab-ci和<a class=link href=https://github.com/drone/drone target=_blank rel=noopener>drone</a>等等，但因为种种原因(比如gitlabci只支持gitlab，drone需要借助其他git仓库的用户权限系统不支持原生裸git)，这里最终还是选择了jenkins进行实验。</p><p>首先要解决的肯定是流程上的问题，就是所谓的cicd流程，参考了一些演讲ppt的做法，不过ppt嘛，你懂的，图画的还是很好看，但是也啰里八嗦的，不够简洁明快，有些地方明明很简单却故意讲的很高深莫测好像很厉害的样子，总之就是看着看着就觉得有点好笑 <a class=link href=http://www.calmkart.com/wp-content/uploads/2019/06/%e6%8a%8a%e5%a4%a7%e4%bc%99%e9%80%97%e4%b9%90%e4%ba%86.jpg target=_blank rel=noopener><img src=images/%e6%8a%8a%e5%a4%a7%e4%bc%99%e9%80%97%e4%b9%90%e4%ba%86.jpg alt></a></p><p>大致流程图我就意思意思吧:</p><p><em><strong>用户提交代码 &mdash;-> Jenkins触发构建 &mdash;-> 编译打包 &mdash;-> 归档成品 &mdash;-> 制作镜像 &mdash;->k8s发布</strong></em></p><p>其中构建触发这一部分因为是用的多分支流水线，觉得还是用触发扫描api由用户在运维平台点击一下比较好。构建因为是用的基于k8s的jenkins，所以同样用了动态的jenkins-slave，这样就可以做到有工作则自动生成jenkins-slave进行编译，无工作则自动销毁jenkins-slave释放资源，从而实现资源的最大化利用和伸缩性。</p><p>首先在k8s中部署jenkins 1. 创建jenkins-master-home pvc</p><pre tabindex=0><code># vim jenkins-master-pvc.yaml

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: jenkins-master-home
  namespace: kube-ops
  labels:
    app: jenkins-master-home
spec:
  storageClassName: rook-ceph-block
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi

# kubectl apply -f jenkins-master-pvc.yaml 
</code></pre><p>2. 创建 rbac</p><pre tabindex=0><code># vim rbac.yaml

apiVersion: v1
kind: ServiceAccount
metadata:
  name: jenkins2
  namespace: kube-ops

---

kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: jenkins2
rules:
  - apiGroups: [&#34;extensions&#34;, &#34;apps&#34;]
    resources: [&#34;deployments&#34;]
    verbs: [&#34;create&#34;, &#34;delete&#34;, &#34;get&#34;, &#34;list&#34;, &#34;watch&#34;, &#34;patch&#34;, &#34;update&#34;]
  - apiGroups: [&#34;&#34;]
    resources: [&#34;services&#34;]
    verbs: [&#34;create&#34;, &#34;delete&#34;, &#34;get&#34;, &#34;list&#34;, &#34;watch&#34;, &#34;patch&#34;, &#34;update&#34;]
  - apiGroups: [&#34;&#34;]
    resources: [&#34;pods&#34;]
    verbs: [&#34;create&#34;,&#34;delete&#34;,&#34;get&#34;,&#34;list&#34;,&#34;patch&#34;,&#34;update&#34;,&#34;watch&#34;]
  - apiGroups: [&#34;&#34;]
    resources: [&#34;pods/exec&#34;]
    verbs: [&#34;create&#34;,&#34;delete&#34;,&#34;get&#34;,&#34;list&#34;,&#34;patch&#34;,&#34;update&#34;,&#34;watch&#34;]
  - apiGroups: [&#34;&#34;]
    resources: [&#34;pods/log&#34;]
    verbs: [&#34;get&#34;,&#34;list&#34;,&#34;watch&#34;]
  - apiGroups: [&#34;&#34;]
    resources: [&#34;secrets&#34;]
    verbs: [&#34;get&#34;]

---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: jenkins2
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: jenkins2
subjects:
  - kind: ServiceAccount
    name: jenkins2
    namespace: kube-ops

# kubectl apply -f rbac.yaml
</code></pre><p>3.创建jenkins deployment和service</p><pre tabindex=0><code># vim jenkins.yaml

---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: jenkins2-deployment
  namespace: kube-ops
spec:
  template:
    metadata:
      labels:
        app: jenkins2
    spec:
      terminationGracePeriodSeconds: 10
      serviceAccountName: jenkins2
      containers:
      - name: jenkins
        image: jenkins/jenkins:lts
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8080
          name: web
          protocol: TCP
        - containerPort: 50000
          name: agent
          protocol: TCP
        resources:
          limits:
            cpu: 4000m
            memory: 8Gi
          requests:
            cpu: 1000m
            memory: 2Gi
        livenessProbe:
          httpGet:
            path: /login
            port: 8080
          initialDelaySeconds: 60
          timeoutSeconds: 5
          failureThreshold: 12
        readinessProbe:
          httpGet:
            path: /login
            port: 8080
          initialDelaySeconds: 60
          timeoutSeconds: 5
          failureThreshold: 12
        volumeMounts:
        - name: jenkinshome
          subPath: jenkins2
          mountPath: /var/jenkins_home
        env:
        - name: LIMITS_MEMORY
          valueFrom:
            resourceFieldRef:
              resource: limits.memory
              divisor: 1Mi
        - name: JAVA_OPTS
          value: -Xmx$(LIMITS_MEMORY)m -XshowSettings:vm -Dhudson.slaves.NodeProvisioner.initialDelay=0 -Dhudson.slaves.NodeProvisioner.MARGIN=50 -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85 -Duser.timezone=Asia/Shanghai
      securityContext:
        fsGroup: 1000
      volumes:
      - name: jenkinshome
        persistentVolumeClaim:
          claimName: jenkins-master-home

---
apiVersion: v1
kind: Service
metadata:
  name: jenkins2
  namespace: kube-ops
  labels:
    app: jenkins2
spec:
  selector:
    app: jenkins2
  type: ClusterIP
  ports:
  - name: web
    port: 8080
    targetPort: web
  - name: agent
    port: 50000
    targetPort: agent

# kubectl apply -f jenkins.yaml
</code></pre><p>这个时候jenkins就已经起起来了，我们给jenkins的webui添加一个ingress负载均衡和服务暴露</p><pre tabindex=0><code># vim kube-ops-ingress.yaml

apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: kube-ops-ingress
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: &#34;false&#34;
  namespace: kube-ops
spec:
  rules:
  - host: k8s-jenkins.example.cn
    http:
      paths:
      - path: /
        backend:
          serviceName: jenkins2
          servicePort: 8080

# kubectl apply -f kube-ops-ingress.yaml
</code></pre><p>这时候因为ingress service是用的master node的externalIp，所以我们可以直接通过修改dns，将k8s-jenkins.example.cn域名指向master node的externalIp，然后直接访问k8s-jenkins.example.cn就可以访问到jenkins服务。(有问题可以查看下kubectl get ingress -o wide &ndash;all-namespaces)</p><p>然后安装常见的插件，进入jenkins后记得再安装如下两个插件 blueOcean(新一代的流水线UI)，kubernetes(k8s slave支持)，Multibranch Scan Webhook Trigger(多分枝流水线扫描触发器)</p><p>安装好之后，进入设置，拉到最下面，选择添加一个云(k8s) <a class=link href=http://www.calmkart.com/wp-content/uploads/2019/06/xzygy.png target=_blank rel=noopener><img src=images/xzygy.png alt>
</a>按如上配置，在页面测试连接k8s正常即可(jenkins服务名这里叫jenkins2，按实际修改)</p><p><strong><em>至于下面的是否添加镜像，我推荐是不在这里添加，而选择用Yaml直接编写添加。原因是，这里添加slave k8s pod tempalte的话，slave编号无法动态化，会导致后以后构建任务等待前任务，无法多slave并行。(很多文章会在这里添加slave pod template，然后用一个自由风格软件项目做例子，那根本无法在实际环境中用的)</em></strong></p><p><strong><em>这里还有个小坑，无论是yaml的slave k8s pod tempalte还是在jenkins设置里页面添加的slave k8s pod template，如果想使用自定义slave image的话，containers: - name 一定要填写成- name: jnlp，否则会不读取自定义slave image而采用官方的<a class=link href=https://github.com/jenkinsci/docker-jnlp-slave target=_blank rel=noopener>docker-jnlp-slave</a>。</em></strong></p><p>接下来我们创建自己的jenkins-jnlp-slave容器，参考官方的<a class=link href=https://github.com/jenkinsci/docker-jnlp-slave target=_blank rel=noopener>docker-jnlp-slave</a> Dockerfile如下</p><pre tabindex=0><code>ARG VERSION=0.0.1
ARG user=jenkins
ARG group=jenkins
ARG uid=1000
ARG gid=1000

ENV HOME /home/${user}
RUN groupadd -g ${gid} ${group}
RUN useradd -d $HOME -u ${uid} -g ${group} ${user}
LABEL maintainer=&#34;calmkart@calmkart.com&#34; Description=&#34;jenkins jnlp slave image&#34; Vendor=&#34;calmkart@calmkart.com&#34; Version=&#34;${VERSION}&#34;

ARG AGENT_WORKDIR=/home/${user}/agent

RUN curl --create-dirs -fsSLo /usr/share/jenkins/slave.jar https://repo.jenkins-ci.org/public/org/jenkins-ci/main/remoting/3.29/remoting-3.29.jar \
  &amp;&amp; chmod 755 /usr/share/jenkins \
  &amp;&amp; chmod 644 /usr/share/jenkins/slave.jar \
  &amp;&amp; rm -rf /etc/yum.repos.d/*

COPY kubectl kubectl
COPY jdk/ ./jdk
COPY maven ./maven
COPY jenkins-slave /usr/local/bin/jenkins-slave
COPY CentOS-Base.repo /etc/yum.repos.d/
COPY epel.repo /etc/yum.repos.d/

RUN yum makecache \
  &amp;&amp; yum install -y unzip.x86_64 \
  &amp;&amp; chmod +x ./kubectl \
  &amp;&amp; chmod +x /usr/local/bin/jenkins-slave \
  &amp;&amp; mv ./kubectl /usr/local/bin/kubectl \
  &amp;&amp; /bin/bash maven/default/install_maven \
  &amp;&amp; /bin/bash jdk/default/install_jdk \
  &amp;&amp; yum install -y nodejs \
  &amp;&amp; yum install -y python36.x86_64 \
  &amp;&amp; yum install -y docker-ce.x86_64 \
  &amp;&amp; yum install -y git \
  &amp;&amp; yum install -y which

USER ${user}
ENV PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/maven/bin:/usr/java/jdk/bin
RUN export PATH=$PATH:/opt/maven/bin:/usr/java/jdk/bin
ENV AGENT_WORKDIR=${AGENT_WORKDIR}
RUN mkdir /home/${user}/.jenkins &amp;&amp; mkdir -p ${AGENT_WORKDIR}

VOLUME /home/${user}/.jenkins
VOLUME ${AGENT_WORKDIR}
WORKDIR /home/${user}

ENTRYPOINT [&#34;jenkins-slave&#34;]
</code></pre><p>这里创建的是一个基于centos的jenkins jnlp slave容器镜像，安装了python2,python3,nodejs,docker,kubectl,maven,git等工具和环境。</p><p>将该镜像build并上传到harbor仓库即可在项目的Jenkinsfile中使用.</p><p>以下是具体待构建项目中jenkins jnlp slave的pod template信息</p><pre tabindex=0><code># vim jnlp-slave-declarative.yaml
metadata:
  namespace: kube-ops
spec:
  containers:
  - name: jnlp
    image: harbor.example.org/example/jenkins-jnlp-slave:v0.0.1
    workingDir: /home/jenkins
    ttyEnabled: true
    privileged: false
    alwaysPullImage: false
    volumeMounts:
    - name: volume-0
      mountPath: /var/run/docker.sock
    - name: volume-1
      mountPath: /home/jenkins/.kube
    - name: volume-2
      mountPath: /home/jenkins
    - name: volume-3
      mountPath: /root/.m2
  volumes:
  - name: volume-0
    hostPath:
      path: /var/run/docker.sock
      type: &#34;&#34;
  - name: volume-1
    hostPath:
      path: /root/.kube
      type: &#34;&#34;
  - name: volume-2
    nfs:
      path: /home/shared/nfs/jenkins-home
      server: 10.1.33.159
  - name: volume-3
    nfs:
      path: /home/shared/nfs/maven-home
      server: 10.1.33.159
</code></pre><p>关于这个slave k8s pod template要解释一些东西，这里挂载了4个volume到slave中，分别是</p><p>1.在slave中调用宿主机的docker命令,用于构造和上传镜像 /var/run/docker.sock -> /var/run/docker.sock</p><p>2.在slave中调用宿主机的kubectl命令,用于在k8s中发布项目(创建deployment和service) /root/.kube -> /home/jenkins/.kube</p><p>3.搭建了一个nfs用于多个slave共享workspace,避免多次clone代码 /home/shared/nfs/jenkins-home -> /home/jenkins</p><p>4.搭建了一个nfs用于多个slave共享本地maven仓库,避免多次下载jar包,同时统一maven配置 /home/shared/nfs/maven-home —> /root/.m2</p><p><em>这里为什么不用ceph呢？原因很简单，因为ceph rbd块存储不支持ReadWriteMany，而cephfs共享存储虽然支持ReadWriteMany但是不支持分区。所以还是采用了最简单的nfs实现共享存储。</em></p><p>在项目的Jenkinsfile中编写如下agent字段调用该pod template的slave</p><pre tabindex=0><code>def label_tag = &#34;slave-${UUID.randomUUID().toString()}&#34;
pipeline {
  agent {
    kubernetes {
      label label_tag
      yamlFile &#39;jnlp-slave-declarative.yaml&#39;
    }
  }
  }
}
</code></pre><p>这是申明式pipeline的用法中比较好的写法，因为如果不单独写一个yaml的话我记得是不支持很多细节语法的.（具体细节参考<a class=link href=https://github.com/jenkinsci/kubernetes-plugin target=_blank rel=noopener>jenkins kubernetes plugin</a>插件说明）</p><p>做到这里之后，我们扫描多分支流水线，就可以发现创建一个新slave处理构建任务，构建完成则自动销毁了。 但这还远远不够，很多细节没有处理，下篇文章再详述编译发布构成和申明式Pipeline Jenkinsfile,以及项目Dockerfile镜像详细写法例子。</p><hr><h2 id=历史评论-4-条>历史评论 (4 条)</h2><p><em>以下评论来自原 WordPress 站点，仅作存档展示。</em></p><blockquote><p><strong>lsprit</strong> (2019-06-14 19:28)</p><p>大神，我知道CI是持续集成，CD是什么啊？</p></blockquote><blockquote><p>↳ <strong>calmkart</strong> (2019-06-17 13:25)</p><p>continuous integration continuous deployment</p></blockquote><blockquote><p><strong>lizhengyi</strong> (2019-06-24 15:37)</p><p>楼主最近看机会吗，我们组正在招聘运维开发工程师，主要负责公司发布系统和监控系统的开发和维护，公司叫省钱快报，办公地点在北二环，地铁5号线雍和宫站附近，薪资待遇业界上游水平，期待您的回复。</p></blockquote><blockquote><p>↳ <strong>calmkart</strong> (2019-06-26 15:06)</p><p>不好意思,年内没有换工作的意向.</p></blockquote></section><footer class=article-footer><section class=article-tags><a href=/tags/cicd/>Cicd</a>
<a href=/tags/devops/>Devops</a>
<a href=/tags/jenkins/>Jenkins</a>
<a href=/tags/k8s/>K8s</a>
<a href=/tags/kubernetes/>Kubernetes</a>
<a href=/tags/%E8%87%AA%E5%AE%9A%E4%B9%89slave/>自定义slave</a></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/posts/2019/05/2019-05-25-kubernetes%E9%9B%86%E7%BE%A4%E4%B8%AD%E6%9C%8D%E5%8A%A1%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%92%8C%E5%A4%96%E9%83%A8%E5%8F%91%E7%8E%B0/><div class=article-details><h2 class=article-title>kubernetes集群中服务的负载均衡和外部发现</h2></div></a></article><article><a href=/posts/2019/05/2019-05-24-kubernetes%E6%90%AD%E5%BB%BA%E5%B9%B6%E4%BD%BF%E7%94%A8rook-ceph%E7%9A%84pv%E5%AD%98%E5%82%A8/><div class=article-details><h2 class=article-title>kubernetes搭建并使用rook/ceph的pv存储</h2></div></a></article><article><a href=/posts/2018/08/2018-08-02-%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%AB%8B%E7%AB%BF%E8%A7%81%E5%BD%B1%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/><div class=article-details><h2 class=article-title>记一次立竿见影的性能优化</h2></div></a></article></div></div></aside><div id=tcomment></div><script src=https://cdn.jsdelivr.net/npm/twikoo@1.6.39/dist/twikoo.all.min.js></script><script>twikoo.init({envId:"calmblog.vercel.app",el:"#tcomment",lang:"zh-CN"})</script><footer class=site-footer><section class=copyright>&copy;
2026 cAlm的个人Blog</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=4.0.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><script type=module>
    import gallery from '\/ts\/gallery.js';

    const articleContent = document.querySelector('.article-content');
    const shouldLoad = articleContent && (articleContent.querySelectorAll('figure').length > 0 || articleContent.querySelectorAll('img.gallery-image').length > 0);
    
    if (shouldLoad) {
        gallery(articleContent);

        const PhotoSwipeLightbox = (await import("https:\/\/cdn.jsdelivr.net\/npm\/photoswipe@5.4.4\/dist\/photoswipe-lightbox.esm.min.js")).default;
        const styleHref = "https:\/\/cdn.jsdelivr.net\/npm\/photoswipe@5.4.4\/dist\/photoswipe.css";

        const styleTag = document.createElement('link');
        styleTag.rel = 'stylesheet';
        styleTag.href = styleHref;
        document.head.appendChild(styleTag);

        const lightbox = new PhotoSwipeLightbox({
            gallerySelector: '.article-content',
            childSelector: 'figure a.image-link',
            pswpModule: () => import("https:\/\/cdn.jsdelivr.net\/npm\/photoswipe@5.4.4\/dist\/photoswipe.esm.min.js")
        });
        lightbox.init();
    }
</script></main></div><script type=text/javascript src=/ts/main.acaf849f2b273f6a8368a58b001f336738d0c948d92e79b116467d0c7515f932.js defer></script></body></html>