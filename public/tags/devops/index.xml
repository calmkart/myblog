<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Devops on cAlm的个人Blog</title>
        <link>http://localhost:1313/tags/devops/</link>
        <description>Recent content in Devops on cAlm的个人Blog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 13 Jun 2019 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/tags/devops/index.xml" rel="self" type="application/rss+xml" /><item>
            <title>kubernetes&#43;jenkins实现现代cicd流水线(一)</title>
            <link>http://localhost:1313/posts/2019/06/2019-06-13-kubernetesjenkins%E5%AE%9E%E7%8E%B0%E7%8E%B0%E4%BB%A3cicd%E6%B5%81%E6%B0%B4%E7%BA%BF%E4%B8%80/</link>
            <pubDate>Thu, 13 Jun 2019 00:00:00 +0000</pubDate>
            <guid>http://localhost:1313/posts/2019/06/2019-06-13-kubernetesjenkins%E5%AE%9E%E7%8E%B0%E7%8E%B0%E4%BB%A3cicd%E6%B5%81%E6%B0%B4%E7%BA%BF%E4%B8%80/</guid>
            <description>&lt;p&gt;前面几篇文章已经谈过在k8s中如何实现rook/ceph持久化存储和服务发现/负载均衡/服务暴露策略，接下来几篇文章将以springboot项目为例，详解如何利用kubernetes容器编排平台实现cicd流水线(devops)。&lt;/p&gt;&#xA;&lt;p&gt;我们根据上面几篇文章已经有了一个k8s集群，常见的的cicd工具有jenkins，gitlab-ci和&lt;a class=&#34;link&#34; href=&#34;https://github.com/drone/drone&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&#xA;    &gt;drone&lt;/a&gt;等等，但因为种种原因(比如gitlabci只支持gitlab，drone需要借助其他git仓库的用户权限系统不支持原生裸git)，这里最终还是选择了jenkins进行实验。&lt;/p&gt;&#xA;&lt;p&gt;首先要解决的肯定是流程上的问题，就是所谓的cicd流程，参考了一些演讲ppt的做法，不过ppt嘛，你懂的，图画的还是很好看，但是也啰里八嗦的，不够简洁明快，有些地方明明很简单却故意讲的很高深莫测好像很厉害的样子，总之就是看着看着就觉得有点好笑 &lt;a class=&#34;link&#34; href=&#34;http://www.calmkart.com/wp-content/uploads/2019/06/%e6%8a%8a%e5%a4%a7%e4%bc%99%e9%80%97%e4%b9%90%e4%ba%86.jpg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&#xA;    &gt;&lt;img src=&#34;images/%e6%8a%8a%e5%a4%a7%e4%bc%99%e9%80%97%e4%b9%90%e4%ba%86.jpg&#34; alt=&#34;&#34; /&gt;&#xA;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;大致流程图我就意思意思吧:&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;用户提交代码 &amp;mdash;-&amp;gt; Jenkins触发构建 &amp;mdash;-&amp;gt; 编译打包 &amp;mdash;-&amp;gt; 归档成品 &amp;mdash;-&amp;gt; 制作镜像 &amp;mdash;-&amp;gt;k8s发布&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;其中构建触发这一部分因为是用的多分支流水线，觉得还是用触发扫描api由用户在运维平台点击一下比较好。构建因为是用的基于k8s的jenkins，所以同样用了动态的jenkins-slave，这样就可以做到有工作则自动生成jenkins-slave进行编译，无工作则自动销毁jenkins-slave释放资源，从而实现资源的最大化利用和伸缩性。&lt;/p&gt;&#xA;&lt;p&gt;首先在k8s中部署jenkins 1. 创建jenkins-master-home pvc&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# vim jenkins-master-pvc.yaml&#xA;&#xA;apiVersion: v1&#xA;kind: PersistentVolumeClaim&#xA;metadata:&#xA;  name: jenkins-master-home&#xA;  namespace: kube-ops&#xA;  labels:&#xA;    app: jenkins-master-home&#xA;spec:&#xA;  storageClassName: rook-ceph-block&#xA;  accessModes:&#xA;  - ReadWriteOnce&#xA;  resources:&#xA;    requests:&#xA;      storage: 100Gi&#xA;&#xA;# kubectl apply -f jenkins-master-pvc.yaml &#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2. 创建 rbac&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# vim rbac.yaml&#xA;&#xA;apiVersion: v1&#xA;kind: ServiceAccount&#xA;metadata:&#xA;  name: jenkins2&#xA;  namespace: kube-ops&#xA;&#xA;---&#xA;&#xA;kind: ClusterRole&#xA;apiVersion: rbac.authorization.k8s.io/v1beta1&#xA;metadata:&#xA;  name: jenkins2&#xA;rules:&#xA;  - apiGroups: [&amp;#34;extensions&amp;#34;, &amp;#34;apps&amp;#34;]&#xA;    resources: [&amp;#34;deployments&amp;#34;]&#xA;    verbs: [&amp;#34;create&amp;#34;, &amp;#34;delete&amp;#34;, &amp;#34;get&amp;#34;, &amp;#34;list&amp;#34;, &amp;#34;watch&amp;#34;, &amp;#34;patch&amp;#34;, &amp;#34;update&amp;#34;]&#xA;  - apiGroups: [&amp;#34;&amp;#34;]&#xA;    resources: [&amp;#34;services&amp;#34;]&#xA;    verbs: [&amp;#34;create&amp;#34;, &amp;#34;delete&amp;#34;, &amp;#34;get&amp;#34;, &amp;#34;list&amp;#34;, &amp;#34;watch&amp;#34;, &amp;#34;patch&amp;#34;, &amp;#34;update&amp;#34;]&#xA;  - apiGroups: [&amp;#34;&amp;#34;]&#xA;    resources: [&amp;#34;pods&amp;#34;]&#xA;    verbs: [&amp;#34;create&amp;#34;,&amp;#34;delete&amp;#34;,&amp;#34;get&amp;#34;,&amp;#34;list&amp;#34;,&amp;#34;patch&amp;#34;,&amp;#34;update&amp;#34;,&amp;#34;watch&amp;#34;]&#xA;  - apiGroups: [&amp;#34;&amp;#34;]&#xA;    resources: [&amp;#34;pods/exec&amp;#34;]&#xA;    verbs: [&amp;#34;create&amp;#34;,&amp;#34;delete&amp;#34;,&amp;#34;get&amp;#34;,&amp;#34;list&amp;#34;,&amp;#34;patch&amp;#34;,&amp;#34;update&amp;#34;,&amp;#34;watch&amp;#34;]&#xA;  - apiGroups: [&amp;#34;&amp;#34;]&#xA;    resources: [&amp;#34;pods/log&amp;#34;]&#xA;    verbs: [&amp;#34;get&amp;#34;,&amp;#34;list&amp;#34;,&amp;#34;watch&amp;#34;]&#xA;  - apiGroups: [&amp;#34;&amp;#34;]&#xA;    resources: [&amp;#34;secrets&amp;#34;]&#xA;    verbs: [&amp;#34;get&amp;#34;]&#xA;&#xA;---&#xA;apiVersion: rbac.authorization.k8s.io/v1beta1&#xA;kind: ClusterRoleBinding&#xA;metadata:&#xA;  name: jenkins2&#xA;roleRef:&#xA;  apiGroup: rbac.authorization.k8s.io&#xA;  kind: ClusterRole&#xA;  name: jenkins2&#xA;subjects:&#xA;  - kind: ServiceAccount&#xA;    name: jenkins2&#xA;    namespace: kube-ops&#xA;&#xA;# kubectl apply -f rbac.yaml&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.创建jenkins deployment和service&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# vim jenkins.yaml&#xA;&#xA;---&#xA;apiVersion: extensions/v1beta1&#xA;kind: Deployment&#xA;metadata:&#xA;  name: jenkins2-deployment&#xA;  namespace: kube-ops&#xA;spec:&#xA;  template:&#xA;    metadata:&#xA;      labels:&#xA;        app: jenkins2&#xA;    spec:&#xA;      terminationGracePeriodSeconds: 10&#xA;      serviceAccountName: jenkins2&#xA;      containers:&#xA;      - name: jenkins&#xA;        image: jenkins/jenkins:lts&#xA;        imagePullPolicy: IfNotPresent&#xA;        ports:&#xA;        - containerPort: 8080&#xA;          name: web&#xA;          protocol: TCP&#xA;        - containerPort: 50000&#xA;          name: agent&#xA;          protocol: TCP&#xA;        resources:&#xA;          limits:&#xA;            cpu: 4000m&#xA;            memory: 8Gi&#xA;          requests:&#xA;            cpu: 1000m&#xA;            memory: 2Gi&#xA;        livenessProbe:&#xA;          httpGet:&#xA;            path: /login&#xA;            port: 8080&#xA;          initialDelaySeconds: 60&#xA;          timeoutSeconds: 5&#xA;          failureThreshold: 12&#xA;        readinessProbe:&#xA;          httpGet:&#xA;            path: /login&#xA;            port: 8080&#xA;          initialDelaySeconds: 60&#xA;          timeoutSeconds: 5&#xA;          failureThreshold: 12&#xA;        volumeMounts:&#xA;        - name: jenkinshome&#xA;          subPath: jenkins2&#xA;          mountPath: /var/jenkins_home&#xA;        env:&#xA;        - name: LIMITS_MEMORY&#xA;          valueFrom:&#xA;            resourceFieldRef:&#xA;              resource: limits.memory&#xA;              divisor: 1Mi&#xA;        - name: JAVA_OPTS&#xA;          value: -Xmx$(LIMITS_MEMORY)m -XshowSettings:vm -Dhudson.slaves.NodeProvisioner.initialDelay=0 -Dhudson.slaves.NodeProvisioner.MARGIN=50 -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85 -Duser.timezone=Asia/Shanghai&#xA;      securityContext:&#xA;        fsGroup: 1000&#xA;      volumes:&#xA;      - name: jenkinshome&#xA;        persistentVolumeClaim:&#xA;          claimName: jenkins-master-home&#xA;&#xA;---&#xA;apiVersion: v1&#xA;kind: Service&#xA;metadata:&#xA;  name: jenkins2&#xA;  namespace: kube-ops&#xA;  labels:&#xA;    app: jenkins2&#xA;spec:&#xA;  selector:&#xA;    app: jenkins2&#xA;  type: ClusterIP&#xA;  ports:&#xA;  - name: web&#xA;    port: 8080&#xA;    targetPort: web&#xA;  - name: agent&#xA;    port: 50000&#xA;    targetPort: agent&#xA;&#xA;# kubectl apply -f jenkins.yaml&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这个时候jenkins就已经起起来了，我们给jenkins的webui添加一个ingress负载均衡和服务暴露&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# vim kube-ops-ingress.yaml&#xA;&#xA;apiVersion: extensions/v1beta1&#xA;kind: Ingress&#xA;metadata:&#xA;  name: kube-ops-ingress&#xA;  annotations:&#xA;    nginx.ingress.kubernetes.io/ssl-redirect: &amp;#34;false&amp;#34;&#xA;  namespace: kube-ops&#xA;spec:&#xA;  rules:&#xA;  - host: k8s-jenkins.example.cn&#xA;    http:&#xA;      paths:&#xA;      - path: /&#xA;        backend:&#xA;          serviceName: jenkins2&#xA;          servicePort: 8080&#xA;&#xA;# kubectl apply -f kube-ops-ingress.yaml&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这时候因为ingress service是用的master node的externalIp，所以我们可以直接通过修改dns，将k8s-jenkins.example.cn域名指向master node的externalIp，然后直接访问k8s-jenkins.example.cn就可以访问到jenkins服务。(有问题可以查看下kubectl get ingress -o wide &amp;ndash;all-namespaces)&lt;/p&gt;&#xA;&lt;p&gt;然后安装常见的插件，进入jenkins后记得再安装如下两个插件 blueOcean(新一代的流水线UI)，kubernetes(k8s slave支持)，Multibranch Scan Webhook Trigger(多分枝流水线扫描触发器)&lt;/p&gt;&#xA;&lt;p&gt;安装好之后，进入设置，拉到最下面，选择添加一个云(k8s) &lt;a class=&#34;link&#34; href=&#34;http://www.calmkart.com/wp-content/uploads/2019/06/xzygy.png&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&#xA;    &gt;&lt;img src=&#34;images/xzygy.png&#34; alt=&#34;&#34; /&gt;&#xA;&lt;/a&gt; 按如上配置，在页面测试连接k8s正常即可(jenkins服务名这里叫jenkins2，按实际修改)&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;em&gt;至于下面的是否添加镜像，我推荐是不在这里添加，而选择用Yaml直接编写添加。原因是，这里添加slave k8s pod tempalte的话，slave编号无法动态化，会导致后以后构建任务等待前任务，无法多slave并行。(很多文章会在这里添加slave pod template，然后用一个自由风格软件项目做例子，那根本无法在实际环境中用的)&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;em&gt;这里还有个小坑，无论是yaml的slave k8s pod tempalte还是在jenkins设置里页面添加的slave k8s pod template，如果想使用自定义slave image的话，containers: - name 一定要填写成- name: jnlp，否则会不读取自定义slave image而采用官方的&lt;a class=&#34;link&#34; href=&#34;https://github.com/jenkinsci/docker-jnlp-slave&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&#xA;    &gt;docker-jnlp-slave&lt;/a&gt;。&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;接下来我们创建自己的jenkins-jnlp-slave容器，参考官方的&lt;a class=&#34;link&#34; href=&#34;https://github.com/jenkinsci/docker-jnlp-slave&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&#xA;    &gt;docker-jnlp-slave&lt;/a&gt; Dockerfile如下&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ARG VERSION=0.0.1&#xA;ARG user=jenkins&#xA;ARG group=jenkins&#xA;ARG uid=1000&#xA;ARG gid=1000&#xA;&#xA;ENV HOME /home/${user}&#xA;RUN groupadd -g ${gid} ${group}&#xA;RUN useradd -d $HOME -u ${uid} -g ${group} ${user}&#xA;LABEL maintainer=&amp;#34;calmkart@calmkart.com&amp;#34; Description=&amp;#34;jenkins jnlp slave image&amp;#34; Vendor=&amp;#34;calmkart@calmkart.com&amp;#34; Version=&amp;#34;${VERSION}&amp;#34;&#xA;&#xA;ARG AGENT_WORKDIR=/home/${user}/agent&#xA;&#xA;RUN curl --create-dirs -fsSLo /usr/share/jenkins/slave.jar https://repo.jenkins-ci.org/public/org/jenkins-ci/main/remoting/3.29/remoting-3.29.jar \&#xA;  &amp;amp;&amp;amp; chmod 755 /usr/share/jenkins \&#xA;  &amp;amp;&amp;amp; chmod 644 /usr/share/jenkins/slave.jar \&#xA;  &amp;amp;&amp;amp; rm -rf /etc/yum.repos.d/*&#xA;&#xA;COPY kubectl kubectl&#xA;COPY jdk/ ./jdk&#xA;COPY maven ./maven&#xA;COPY jenkins-slave /usr/local/bin/jenkins-slave&#xA;COPY CentOS-Base.repo /etc/yum.repos.d/&#xA;COPY epel.repo /etc/yum.repos.d/&#xA;&#xA;RUN yum makecache \&#xA;  &amp;amp;&amp;amp; yum install -y unzip.x86_64 \&#xA;  &amp;amp;&amp;amp; chmod +x ./kubectl \&#xA;  &amp;amp;&amp;amp; chmod +x /usr/local/bin/jenkins-slave \&#xA;  &amp;amp;&amp;amp; mv ./kubectl /usr/local/bin/kubectl \&#xA;  &amp;amp;&amp;amp; /bin/bash maven/default/install_maven \&#xA;  &amp;amp;&amp;amp; /bin/bash jdk/default/install_jdk \&#xA;  &amp;amp;&amp;amp; yum install -y nodejs \&#xA;  &amp;amp;&amp;amp; yum install -y python36.x86_64 \&#xA;  &amp;amp;&amp;amp; yum install -y docker-ce.x86_64 \&#xA;  &amp;amp;&amp;amp; yum install -y git \&#xA;  &amp;amp;&amp;amp; yum install -y which&#xA;&#xA;USER ${user}&#xA;ENV PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/maven/bin:/usr/java/jdk/bin&#xA;RUN export PATH=$PATH:/opt/maven/bin:/usr/java/jdk/bin&#xA;ENV AGENT_WORKDIR=${AGENT_WORKDIR}&#xA;RUN mkdir /home/${user}/.jenkins &amp;amp;&amp;amp; mkdir -p ${AGENT_WORKDIR}&#xA;&#xA;VOLUME /home/${user}/.jenkins&#xA;VOLUME ${AGENT_WORKDIR}&#xA;WORKDIR /home/${user}&#xA;&#xA;ENTRYPOINT [&amp;#34;jenkins-slave&amp;#34;]&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里创建的是一个基于centos的jenkins jnlp slave容器镜像，安装了python2,python3,nodejs,docker,kubectl,maven,git等工具和环境。&lt;/p&gt;&#xA;&lt;p&gt;将该镜像build并上传到harbor仓库即可在项目的Jenkinsfile中使用.&lt;/p&gt;&#xA;&lt;p&gt;以下是具体待构建项目中jenkins jnlp slave的pod template信息&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# vim jnlp-slave-declarative.yaml&#xA;metadata:&#xA;  namespace: kube-ops&#xA;spec:&#xA;  containers:&#xA;  - name: jnlp&#xA;    image: harbor.example.org/example/jenkins-jnlp-slave:v0.0.1&#xA;    workingDir: /home/jenkins&#xA;    ttyEnabled: true&#xA;    privileged: false&#xA;    alwaysPullImage: false&#xA;    volumeMounts:&#xA;    - name: volume-0&#xA;      mountPath: /var/run/docker.sock&#xA;    - name: volume-1&#xA;      mountPath: /home/jenkins/.kube&#xA;    - name: volume-2&#xA;      mountPath: /home/jenkins&#xA;    - name: volume-3&#xA;      mountPath: /root/.m2&#xA;  volumes:&#xA;  - name: volume-0&#xA;    hostPath:&#xA;      path: /var/run/docker.sock&#xA;      type: &amp;#34;&amp;#34;&#xA;  - name: volume-1&#xA;    hostPath:&#xA;      path: /root/.kube&#xA;      type: &amp;#34;&amp;#34;&#xA;  - name: volume-2&#xA;    nfs:&#xA;      path: /home/shared/nfs/jenkins-home&#xA;      server: 10.1.33.159&#xA;  - name: volume-3&#xA;    nfs:&#xA;      path: /home/shared/nfs/maven-home&#xA;      server: 10.1.33.159&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;关于这个slave k8s pod template要解释一些东西，这里挂载了4个volume到slave中，分别是&lt;/p&gt;&#xA;&lt;p&gt;1.在slave中调用宿主机的docker命令,用于构造和上传镜像 /var/run/docker.sock -&amp;gt; /var/run/docker.sock&lt;/p&gt;&#xA;&lt;p&gt;2.在slave中调用宿主机的kubectl命令,用于在k8s中发布项目(创建deployment和service) /root/.kube -&amp;gt; /home/jenkins/.kube&lt;/p&gt;&#xA;&lt;p&gt;3.搭建了一个nfs用于多个slave共享workspace,避免多次clone代码 /home/shared/nfs/jenkins-home -&amp;gt; /home/jenkins&lt;/p&gt;&#xA;&lt;p&gt;4.搭建了一个nfs用于多个slave共享本地maven仓库,避免多次下载jar包,同时统一maven配置 /home/shared/nfs/maven-home —&amp;gt; /root/.m2&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;这里为什么不用ceph呢？原因很简单，因为ceph rbd块存储不支持ReadWriteMany，而cephfs共享存储虽然支持ReadWriteMany但是不支持分区。所以还是采用了最简单的nfs实现共享存储。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;在项目的Jenkinsfile中编写如下agent字段调用该pod template的slave&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;def label_tag = &amp;#34;slave-${UUID.randomUUID().toString()}&amp;#34;&#xA;pipeline {&#xA;  agent {&#xA;    kubernetes {&#xA;      label label_tag&#xA;      yamlFile &amp;#39;jnlp-slave-declarative.yaml&amp;#39;&#xA;    }&#xA;  }&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这是申明式pipeline的用法中比较好的写法，因为如果不单独写一个yaml的话我记得是不支持很多细节语法的.（具体细节参考&lt;a class=&#34;link&#34; href=&#34;https://github.com/jenkinsci/kubernetes-plugin&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&#xA;    &gt;jenkins kubernetes plugin&lt;/a&gt;插件说明）&lt;/p&gt;&#xA;&lt;p&gt;做到这里之后，我们扫描多分支流水线，就可以发现创建一个新slave处理构建任务，构建完成则自动销毁了。 但这还远远不够，很多细节没有处理，下篇文章再详述编译发布构成和申明式Pipeline Jenkinsfile,以及项目Dockerfile镜像详细写法例子。&lt;/p&gt;</description>
        </item><item>
            <title>记一次立竿见影的性能优化</title>
            <link>http://localhost:1313/posts/2018/08/2018-08-02-%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%AB%8B%E7%AB%BF%E8%A7%81%E5%BD%B1%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</link>
            <pubDate>Thu, 02 Aug 2018 00:00:00 +0000</pubDate>
            <guid>http://localhost:1313/posts/2018/08/2018-08-02-%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%AB%8B%E7%AB%BF%E8%A7%81%E5%BD%B1%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</guid>
            <description>&lt;p&gt;通过一点细微代码的修改,将某系统首页载入时间缩短了10倍有余.&lt;/p&gt;&#xA;&lt;p&gt;系统首页大致这样&lt;/p&gt;&#xA;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://www.calmkart.com/wp-content/uploads/2018/08/201882204014dama.png&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&#xA;    &gt;&lt;img src=&#34;images/201882204014dama.png&#34; alt=&#34;&#34; /&gt;&#xA;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;逻辑是读取后台的所有服务列表,判断用户是否有权限,有权限则交给前端用ztree显示,并可进行部署操作,但因为服务太多,遍历服务后判断用户是否有权限后台耗时太长,用chrome查了下,后台数据处理费时2000ms,这样首页就载入的太慢了.&lt;/p&gt;&#xA;&lt;p&gt;第一步,查代码,原始代码如下:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;@login_required&#xA;def services(request):&#xA;    user = request.user&#xA;    _online_apps = App.objects.filter(app_env=&amp;#39;online&amp;#39;)&#xA;    _test_apps = App.objects.filter(app_env=&amp;#39;test&amp;#39;)&#xA;    _dev_apps = App.objects.filter(app_env=&amp;#39;dev&amp;#39;)&#xA;&#xA;    online_apps = [a for a in _online_apps if user.has_perm(&amp;#39;deploy_perm&amp;#39;, a) or is_admin_by_group(user.username)]&#xA;    test_apps = [a for a in _test_apps if user.has_perm(&amp;#39;deploy_perm&amp;#39;, a) or is_admin_by_group(user.username)]&#xA;    dev_apps = [a for a in _dev_apps if user.has_perm(&amp;#39;deploy_perm&amp;#39;, a) or is_admin_by_group(user.username)]&#xA;&#xA;    online_apps_name = [{&amp;#39;name&amp;#39;:app.app_name, &amp;#39;id&amp;#39;:app.id} for app in online_apps]&#xA;    test_apps_name = [{&amp;#39;name&amp;#39;:app.app_name, &amp;#39;id&amp;#39;:app.id} for app in test_apps]&#xA;    dev_apps_name = [{&amp;#39;name&amp;#39;:app.app_name, &amp;#39;id&amp;#39;:app.id} for app in dev_apps]&#xA;    nodes = [&#xA;                {&amp;#39;name&amp;#39;:&amp;#39;online&amp;#39;,&#xA;                 &amp;#39;open&amp;#39;:&amp;#39;true&amp;#39;,&#xA;                 &amp;#39;children&amp;#39;:online_apps_name&#xA;                },&#xA;                {&amp;#39;name&amp;#39;:&amp;#39;test&amp;#39;,&#xA;                 &amp;#39;open&amp;#39;:&amp;#39;false&amp;#39;,&#xA;                 &amp;#39;children&amp;#39;:test_apps_name&#xA;                },&#xA;                {&amp;#39;name&amp;#39;:&amp;#39;dev&amp;#39;,&#xA;                 &amp;#39;open&amp;#39;:&amp;#39;false&amp;#39;,&#xA;                 &amp;#39;children&amp;#39;:dev_apps_name&#xA;                }&#xA;    ];&#xA;    return render(request, &amp;#39;services/services.html&amp;#39;, {&amp;#39;nodes&amp;#39;: json.dumps(nodes)})&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;也没什么复杂的,就是django models + django-guardian权限控制,然后返回数据给ztree生成树结构.&lt;/p&gt;&#xA;&lt;p&gt;初步设想是因为列表生成式太多导致速度慢,写测试代码做测试&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;python manage.py shell&#xA;&#xA;&amp;gt;&amp;gt;&amp;gt; import time&#xA;&amp;gt;&amp;gt;&amp;gt; from django.contrib.auth.models import User&#xA;&amp;gt;&amp;gt;&amp;gt; from services.views import new_service&#xA;&amp;gt;&amp;gt;&amp;gt; def test(user):&#xA;...     start = time.time()&#xA;...     new_service(user)&#xA;...     stop = time.time()&#xA;...     print stop-start&#xA;...&#xA;&amp;gt;&amp;gt;&amp;gt; pengng = User.objects.get(name=&amp;#39;pengng&amp;#39;)&#xA;&amp;gt;&amp;gt;&amp;gt; test(pengng)&#xA;1.93502497673&#xA;&amp;gt;&amp;gt;&amp;gt; test(pengng)&#xA;1.89282894135&#xA;&amp;gt;&amp;gt;&amp;gt; test(pengng)&#xA;2.14076519012&#xA;&amp;gt;&amp;gt;&amp;gt; test(pengng)&#xA;1.85515809059&#xA;&amp;gt;&amp;gt;&amp;gt; test(pengng)&#xA;1.91108703613&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;发现处理时间大致在1.8-1.9s之间,然后直接将上述原始代码第一步拆了出来&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#仅测试这一步&#xA;online_apps = [a for a in _online_apps if user.has_perm(&amp;#39;deploy_perm&amp;#39;, a) or is_admin_by_group(user.username)]&#xA;&#xA;#发现时间在1.2秒左右&#xA;&amp;gt;&amp;gt;&amp;gt; test(pengng)&#xA;1.25127100945&#xA;&amp;gt;&amp;gt;&amp;gt; test(pengng)&#xA;1.27178192139&#xA;&amp;gt;&amp;gt;&amp;gt; test(pengng)&#xA;1.22848701477&#xA;&amp;gt;&amp;gt;&amp;gt; test(pengng)&#xA;1.25300002098&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;继续分拆,发现是这个user.has_perm(&amp;lsquo;deploy_perm&amp;rsquo;,a)的guardian获取权限消耗了大量的时间 然后想起这个系统里权限都是以group来赋权的,获取用户对于服务的权限要先经过组再到服务,先遍历服务再单独查看用户是否有该组权限导致重复遍历太多,其实直接获取用户对应的所有拥有权限的服务对象即可(get_objects_for_user()方法),尝试修改代码&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;@login_required&#xA;def services(request):&#xA;    user = request.user&#xA;&#xA;    if is_admin_by_group(user.username):&#xA;        online_apps_name = [{&amp;#39;name&amp;#39;: a.app_name, &amp;#39;id&amp;#39;: a.id}&#xA;                            for a in App.objects.filter(app_env=&amp;#39;online&amp;#39;)]&#xA;        test_apps_name = [{&amp;#39;name&amp;#39;: a.app_name, &amp;#39;id&amp;#39;: a.id}&#xA;                          for a in App.objects.filter(app_env=&amp;#39;test&amp;#39;)]&#xA;        dev_apps_name = [{&amp;#39;name&amp;#39;: a.app_name, &amp;#39;id&amp;#39;: a.id}&#xA;                         for a in App.objects.filter(app_env=&amp;#39;dev&amp;#39;)]&#xA;    else:&#xA;        online_apps_name = [{&amp;#39;name&amp;#39;: a.app_name, &amp;#39;id&amp;#39;: a.id} for a in get_objects_for_user(&#xA;            user, &amp;#39;deploy_perm&amp;#39;, klass=App) if a.app_env == &amp;#34;online&amp;#34;]&#xA;        test_apps_name = [{&amp;#39;name&amp;#39;: a.app_name, &amp;#39;id&amp;#39;: a.id} for a in get_objects_for_user(&#xA;            user, &amp;#39;deploy_perm&amp;#39;, klass=App) if a.app_env == &amp;#34;test&amp;#34;]&#xA;        dev_apps_name = [{&amp;#39;name&amp;#39;: a.app_name, &amp;#39;id&amp;#39;: a.id} for a in get_objects_for_user(&#xA;            user, &amp;#39;deploy_perm&amp;#39;, klass=App) if a.app_env == &amp;#34;dev&amp;#34;]&#xA;&#xA;    nodes = [&#xA;        {&amp;#39;name&amp;#39;: &amp;#39;online&amp;#39;,&#xA;                 &amp;#39;open&amp;#39;: &amp;#39;true&amp;#39;,&#xA;                 &amp;#39;children&amp;#39;: online_apps_name&#xA;         },&#xA;        {&amp;#39;name&amp;#39;: &amp;#39;test&amp;#39;,&#xA;                 &amp;#39;open&amp;#39;: &amp;#39;false&amp;#39;,&#xA;                 &amp;#39;children&amp;#39;: test_apps_name&#xA;         },&#xA;        {&amp;#39;name&amp;#39;: &amp;#39;dev&amp;#39;,&#xA;                 &amp;#39;open&amp;#39;: &amp;#39;false&amp;#39;,&#xA;                 &amp;#39;children&amp;#39;: dev_apps_name&#xA;         }&#xA;    ]&#xA;    return render(request, &amp;#39;services/services.html&amp;#39;, {&amp;#39;nodes&amp;#39;: json.dumps(nodes)})&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后重载文件&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; reload(services.views)&#xA;&amp;lt;module &amp;#39;services.views&amp;#39; from &amp;#39;/home/**/***/services/views.py&amp;#39;&amp;gt;&#xA;&amp;gt;&amp;gt;&amp;gt; test(pengng)&#xA;0.0817279815674&#xA;&amp;gt;&amp;gt;&amp;gt; test(pengng)&#xA;0.0788700580597&#xA;&amp;gt;&amp;gt;&amp;gt; test(pengng)&#xA;0.0756318569183&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;立竿见影,瞬间从2秒降低到了0.08秒左右 &lt;a class=&#34;link&#34; href=&#34;http://www.calmkart.com/wp-content/uploads/2018/08/%e4%bc%81%e4%b8%9a%e5%be%ae%e4%bf%a1%e6%88%aa%e5%9b%be_008058b2-bd81-4a9c-8442-63afc75ac870.png&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&#xA;    &gt;&lt;img src=&#34;images/%e4%bc%81%e4%b8%9a%e5%be%ae%e4%bf%a1%e6%88%aa%e5%9b%be_008058b2-bd81-4a9c-8442-63afc75ac870.png&#34; alt=&#34;&#34; /&gt;&#xA;&lt;/a&gt;收工&lt;/p&gt;</description>
        </item></channel>
</rss>
