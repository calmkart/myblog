<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Ceph on cAlm的个人Blog</title>
        <link>http://localhost:1313/tags/ceph/</link>
        <description>Recent content in Ceph on cAlm的个人Blog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <lastBuildDate>Fri, 24 May 2019 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/tags/ceph/index.xml" rel="self" type="application/rss+xml" /><item>
            <title>kubernetes搭建并使用rook/ceph的pv存储</title>
            <link>http://localhost:1313/posts/2019/05/2019-05-24-kubernetes%E6%90%AD%E5%BB%BA%E5%B9%B6%E4%BD%BF%E7%94%A8rook-ceph%E7%9A%84pv%E5%AD%98%E5%82%A8/</link>
            <pubDate>Fri, 24 May 2019 00:00:00 +0000</pubDate>
            <guid>http://localhost:1313/posts/2019/05/2019-05-24-kubernetes%E6%90%AD%E5%BB%BA%E5%B9%B6%E4%BD%BF%E7%94%A8rook-ceph%E7%9A%84pv%E5%AD%98%E5%82%A8/</guid>
            <description>&lt;p&gt;k8s中pod的存储在非单节点是不支持hostpath的，都得用各种分布式存储来实现.每个pvc对应的pv手工创建也很不现实,试了下rook-ceph分布式存储的搞法，感觉不错.其中也还是遇到了很多坑,这里稍微记录一下.&lt;/p&gt;&#xA;&lt;p&gt;首先有一个三个节点的k8s集群 &lt;a class=&#34;link&#34; href=&#34;http://www.calmkart.com/wp-content/uploads/2019/05/111.png&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&#xA;    &gt;&lt;img src=&#34;images/111.png&#34; alt=&#34;&#34; /&gt;&#xA;&lt;/a&gt; 首先创建rook-ceph-common&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;wget https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/ceph/common.yaml&#xA;kubectl apply -f common.yaml&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后创建rook-ceph-operator&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;wget https://raw.githubusercontent.com/rook/rook/release-1.0/cluster/examples/kubernetes/ceph/operator.yaml&#xA;kubectl apply -f operator.yaml&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;以上两步基本上不会出啥问题,标准配置 接下来创建cluster的问题比较多,贴上我的配置&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;vim cluster.yaml&#xA;&#xA;apiVersion: ceph.rook.io/v1&#xA;kind: CephCluster&#xA;metadata:&#xA;  name: rook-ceph&#xA;  namespace: rook-ceph&#xA;spec:&#xA;  cephVersion:&#xA;    image: ceph/ceph:v14.2.1-20190430&#xA;    allowUnsupported: true&#xA;  #设置data路径到自己规划的路径&#xA;  dataDirHostPath: /home/shared/rook&#xA;  mon:&#xA;    count: 3&#xA;    allowMultiplePerNode: true&#xA;  dashboard:&#xA;    enabled: true&#xA;    port: 8443&#xA;    urlPrefix: /&#xA;    #关闭https&#xA;    ssl: false&#xA;  network:&#xA;    #如要在k8s集群外使用,这里可以打开&#xA;    hostNetwork: false&#xA;  rbdMirroring:&#xA;    workers: 0&#xA;  storage:&#xA;    #全节点使用&#xA;    useAllNodes: true&#xA;    useAllDevices: false&#xA;    deviceFilter:&#xA;    config:&#xA;      osdsPerDevice: &amp;#34;1&amp;#34;&#xA;    directories:&#xA;    - path: /home/shared/rook&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl apply -f cluster.yaml&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看部署情况 &lt;a class=&#34;link&#34; href=&#34;http://www.calmkart.com/wp-content/uploads/2019/05/2.png&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&#xA;    &gt;&lt;img src=&#34;images/2.png&#34; alt=&#34;&#34; /&gt;&#xA;&lt;/a&gt; 这样就基本上没问题了,k8s中的每个Node会启两个pod(rook-ceph-agent和rook-discover),并且mgr和osd都没问题。 然后给ceph-dashboard提供NodePort的外部访问service&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;vim dashboard-external-http.yaml&#xA;&#xA;apiVersion: v1&#xA;kind: Service&#xA;metadata:&#xA;  name: rook-ceph-mgr-dashboard-external-https&#xA;  namespace: rook-ceph&#xA;  labels:&#xA;    app: rook-ceph-mgr&#xA;    rook_cluster: rook-ceph&#xA;spec:&#xA;  ports:&#xA;  - name: dashboard&#xA;    port: 8443&#xA;    protocol: TCP&#xA;    targetPort: 8443&#xA;  selector:&#xA;    app: rook-ceph-mgr&#xA;    rook_cluster: rook-ceph&#xA;  sessionAffinity: None&#xA;  type: NodePort&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl apply -f dashboard-external-https.yaml&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后查看下service的情况,是否正常 &lt;a class=&#34;link&#34; href=&#34;http://www.calmkart.com/wp-content/uploads/2019/05/3.png&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&#xA;    &gt;&lt;img src=&#34;images/3.png&#34; alt=&#34;&#34; /&gt;&#xA;&lt;/a&gt; 这样就对了,可以访问一下http://&lt;!-- raw HTML omitted --&gt;:&lt;!-- raw HTML omitted --&gt;，看看是不是能进ceph-dashboard&lt;/p&gt;&#xA;&lt;p&gt;一般情况下问题不大,查看admin的默认密码&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl -n rook-ceph get secret rook-ceph-dashboard-password -o jsonpath=&amp;#34;{[&amp;#39;data&amp;#39;][&amp;#39;password&amp;#39;]}&amp;#34; | base64 --decode &amp;amp;&amp;amp; echo&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;但是admin登陆进去了之后，肯定会疯狂500错误，查了下官方的issue，这里有bug。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;解决办法是:&lt;/strong&gt; &lt;strong&gt;在dashboard里创建一个新role角色(右上角用户管理,roles)，把权限全钩上，然后去掉iscsi的所有权限。&lt;/strong&gt; &lt;strong&gt;接着创建一个新用户,绑定这个新的role角色,最后用新用户登陆&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;接着创建pool和storage用于自动生成pvc匹配的pv&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;vim storageclass.yaml&#xA;&#xA;apiVersion: ceph.rook.io/v1&#xA;kind: CephBlockPool&#xA;metadata:&#xA;  name: replicapool&#xA;  namespace: rook-ceph&#xA;spec:&#xA;  replicated:&#xA;    size: 2&#xA;---&#xA;apiVersion: storage.k8s.io/v1&#xA;kind: StorageClass&#xA;metadata:&#xA;   name: rook-ceph-block&#xA;provisioner: ceph.rook.io/block&#xA;parameters:&#xA;  blockPool: replicapool&#xA;  clusterNamespace: rook-ceph&#xA;  fstype: xfs&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl apply -f storagecalss.yaml&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;创建pool和storage之后通过dashboard或者命令 kubectl get cephcluster -n rook-ceph 查看一下集群是否health，如果是health就没毛病了&lt;/p&gt;&#xA;&lt;p&gt;最后测试一下申请一个pvc看看是否会自动生成pv与之绑定&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;apiVersion: v1&#xA;kind: PersistentVolumeClaim&#xA;metadata:&#xA;  name: jenkins-home&#xA;  namespace: kube-ops&#xA;  labels:&#xA;    app: jenkins-home&#xA;spec:&#xA;  storageClassName: rook-ceph-block&#xA;  accessModes:&#xA;  - ReadWriteOnce&#xA;  resources:&#xA;    requests:&#xA;      storage: 20Gi&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://www.calmkart.com/wp-content/uploads/2019/05/%e4%bc%81%e4%b8%9a%e5%be%ae%e4%bf%a1%e6%88%aa%e5%9b%be_dd2a2f8b-10fb-4f3f-8d21-bbaa31a4ba7d.png&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&#xA;    &gt;&lt;img src=&#34;images/%e4%bc%81%e4%b8%9a%e5%be%ae%e4%bf%a1%e6%88%aa%e5%9b%be_dd2a2f8b-10fb-4f3f-8d21-bbaa31a4ba7d.png&#34; alt=&#34;&#34; /&gt;&#xA;&lt;/a&gt; 可见，管用了.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;外加一些小tips:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;如果rook-ceph配置有误需要还原重新配置,一定要遵循官方的清理步骤 &lt;a class=&#34;link&#34; href=&#34;https://rook.github.io/docs/rook/v1.0/ceph-teardown.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&#xA;    &gt;https://rook.github.io/docs/rook/v1.0/ceph-teardown.html&lt;/a&gt; 切记要删除掉所有k8s的node上配置的data文件夹,不然会导致新集群无法初始化.&lt;/p&gt;&#xA;&lt;p&gt;创建不出pod很多都是权限原因或者node无法调度,需要检查下rbac权限设置或者各个node的情况.&lt;/p&gt;&#xA;&lt;p&gt;最后附上rook项目的github地址: &lt;a class=&#34;link&#34; href=&#34;https://github.com/rook/rook&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&#xA;    &gt;https://github.com/rook/rook&lt;/a&gt;&lt;/p&gt;</description>
        </item></channel>
</rss>
